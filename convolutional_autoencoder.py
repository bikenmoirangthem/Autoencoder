# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oqrc5xXkovfD6Fyu8wduVdDpMpHMpYNH
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose
import tensorflow as tf

from tensorflow.keras.datasets import mnist
# loading MNIST data and normalizing
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train/255., x_test/255.

# reshaping the training and testing data
x_train = x_train.reshape(len(x_train), 28, 28, 1)
x_test = x_test.reshape(len(x_test), 28, 28, 1)

print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)

# Autoencoder model
inputs = Input(shape = (28, 28, 1), name = 'input_image')
x = Conv2D(64, (3, 3), strides=(1, 1), padding='valid', activation='relu')(inputs)
x = Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
x = Conv2D(16, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
encoded = MaxPooling2D(pool_size=(2, 2))(x)

x = UpSampling2D((2, 2))(encoded)
x = Conv2DTranspose(16, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
x = Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
x = UpSampling2D((2, 2))(x)
x = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='valid', activation='relu')(x)
decoded = Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='valid', activation='sigmoid')(x)
  
autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded, name='autoencoder')
autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

autoencoder.summary()

# Plot the model as a Graph
tf.keras.utils.plot_model(autoencoder, 'mnist.png', show_shapes=True, rankdir="LR")     #rankdir='TB' for vertical Graph

# training the autoencoder for 50 epochs
model_history = autoencoder.fit(x_train, x_train,
                                epochs=50,
                                batch_size=128,
                                shuffle=True,
                                validation_data=(x_test, x_test)
                                )

# Plotting the Training and Validation loss
import matplotlib.pyplot as plt
train_loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

epochs = range(len(train_loss))

plt.plot(epochs, train_loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.legend(loc=0)
plt.title('Training and Validation loss')
plt.figure()
plt.show()

decoded_images = autoencoder.predict(x_test)

n = 10
plt.figure(figsize=(20, 2))
for i in range(1, n):
  # display original image
  ax = plt.subplot(2, n, i)
  plt.imshow(x_test[i].reshape(28, 28))
  plt.gray()
  plt.axis('off')

  # display reconstructed image
  ax = plt.subplot(2, n, i + n)
  plt.imshow(decoded_images[i].reshape(28, 28))
  plt.gray()
  plt.axis('off')

plt.show()