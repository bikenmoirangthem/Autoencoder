# -*- coding: utf-8 -*-
"""image_denoising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d_8qA5CP3_47cf0gUjsOHbou3q7HVBTV
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose
import tensorflow as tf

# autoencoder model
inputs = Input(shape = (28, 28, 1), name = 'input_image')
x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(inputs)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)
encoded = MaxPooling2D(pool_size=(2, 2), padding='same')(x)

x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation='relu')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)
x = UpSampling2D((2, 2))(x)
decoded = Conv2D(1, (3, 3), strides=(1, 1), padding='same', activation='sigmoid')(x)
  
autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded, name='autoencoder')
autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

autoencoder.summary()

# Plot the model as a Graph
tf.keras.utils.plot_model(autoencoder, 'mnist.png', show_shapes=True, rankdir="LR")     #rankdir='TB' for vertical Graph

# importing mnist dataset
from tensorflow.keras.datasets import mnist
import numpy as np

# loading MNIST dataset and normalizing
(x_train, _), (x_test, _) = mnist.load_data()
x_train, x_test = x_train/255., x_test/255.

x_train = x_train.reshape(len(x_train), 28, 28, 1)
x_test = x_test.reshape(len(x_test), 28, 28, 1)

# adding gaussian noise to the images
noise_factor = 0.4
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)

x_train_noisy = np.clip(x_train_noisy, 0.0, 1.0)
x_test_noisy = np.clip(x_test_noisy, 0.0, 1.0)

import matplotlib.pyplot as plt
n = 10
plt.figure(figsize=(20, 2))
for i in range(1, n):
  # display noisy image
  ax = plt.subplot(1, n, i)
  plt.imshow(x_train_noisy[i].ireshape(28, 28))
  plt.gray()
  plt.axis('off')

plt.show()

print('x_train shape:', x_train_noisy.shape)
print('x_test shape:', x_test_noisy.shape)

# train the autoencoder for 50 epochs
model_history = autoencoder.fit(x_train, x_train,
                                epochs=50,
                                batch_size=32,
                                shuffle=True,
                                validation_data=(x_test, x_test)
                                )

# Plotting the training and validation loss
import matplotlib.pyplot as plt
train_loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

epochs = range(len(train_loss))

plt.plot(epochs, train_loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.legend(loc=0)
plt.title('Training and Validation loss')
plt.figure()
plt.show()

decoded_images = autoencoder.predict(x_test_noisy)

n = 10
plt.figure(figsize=(20, 2))
for i in range(1, n):
  # display noisy image
  ax = plt.subplot(2, n, i)
  plt.imshow(x_test_noisy[i].reshape(28, 28))
  plt.gray()
  plt.axis('off')

  # display denoise image
  ax = plt.subplot(2, n, i + n)
  plt.imshow(decoded_images[i].reshape(28, 28))
  plt.gray()
  plt.axis('off')

plt.show()

